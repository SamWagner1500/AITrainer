{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Fraud Machine Learning Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: Higher precision means lower false positives  \n",
    "Recall: Higher recall means lower false negatives  \n",
    "F1-Score: Balance of both, F1 Score = 2 * (Precision * Recall) / (Precision + Recall)  \n",
    "Base Data: All data points\n",
    "Balanced Data: Undersampling the legitimate transactions to have a 50/50 split of legitimate vs fraudulent. Will usually improve the fraudulent accuracy while decreasing the legitimate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "df.dropna(inplace = True)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive analysis\n",
    "import matplotlib.pyplot as plt\n",
    "df_hist = df\n",
    "df_hist\n",
    "plt.close()\n",
    "\n",
    "def generateGraphOne(column_name):\n",
    "    fig, ax = plt.subplots(figsize=(2, 1))\n",
    "    df_hist[column_name].hist(bins=30, ax=ax)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Histogram of {column_name}')\n",
    "    plt.show()\n",
    "#generateGraphOne('Amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df_a = df[['class', 'Amount']].copy()\n",
    "def generateGraphTwo():\n",
    "\n",
    "    amount_bins = [0,10, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500, float('inf')]\n",
    "    labels = ['0-10','11-25', '26-50', '51-75', '76-100', '101-125', '126-150', '151-175', '176-200',\n",
    "            '201-225', '226-250', '251-275', '276-300', '301-325', '326-350', '351-375',\n",
    "            '376-400', '401-425', '426-450', '451-475', '476-500', 'Above 500']\n",
    "\n",
    "    # Categorize the amounts into bins for each class separately\n",
    "    df_a['Amount_Category'] = pd.cut(df_a[df_a['class'] == 0]['Amount'], bins=amount_bins, labels=labels, right=True)\n",
    "    df_a['Amount_Category_Fraud'] = pd.cut(df_a[df_a['class'] == 1]['Amount'], bins=amount_bins, labels=labels, right=True)\n",
    "\n",
    "    # Count the occurrences of each category for each class\n",
    "    category_counts_legitimate = df_a[df_a['class'] == 0]['Amount_Category'].value_counts()\n",
    "    category_counts_fraudulent = df_a[df_a['class'] == 1]['Amount_Category_Fraud'].value_counts()\n",
    "\n",
    "    # Create two subplots side by side for legitimate and fraudulent transactions\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Plot for legitimate transactions\n",
    "    sns.countplot(x='Amount_Category', data=df_a[df_a['class'] == 0], order=labels, palette='viridis', ax=ax1)\n",
    "    ax1.set_xlabel('Transaction Amount Range')\n",
    "    ax1.set_ylabel('Number of Transactions')\n",
    "    ax1.set_title('Number of Transactions for Different Transaction Amount Ranges (Legitimate)')\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "    for index, value in enumerate(category_counts_legitimate):\n",
    "        ax1.text(index, value, str(value), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    # Plot for fraudulent transactions\n",
    "    sns.countplot(x='Amount_Category_Fraud', data=df_a[df_a['class'] == 1], order=labels, palette='viridis', ax=ax2)\n",
    "    ax2.set_xlabel('Transaction Amount Range')\n",
    "    ax2.set_ylabel('Number of Transactions')\n",
    "    ax2.set_title('Number of Transactions for Different Transaction Amount Ranges (Fraudulent)')\n",
    "    ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "    for index, value in enumerate(category_counts_fraudulent):\n",
    "        ax2.text(index, value, str(value), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nondescriptive methods\n",
    "#Shrinking the outlier in the amount column\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "new_df = df\n",
    "new_df.dropna(inplace = True)\n",
    "new_df['Amount'] = RobustScaler().fit_transform(new_df['Amount'].to_numpy().reshape(-1,1))\n",
    "\n",
    "#Standardizing time\n",
    "time = new_df['Time']\n",
    "new_df['Time'] = (time - time.min()) / (time.max() - time.min())\n",
    "\n",
    "#Randomizing dataset\n",
    "new_df = new_df.sample(frac=1)\n",
    "#new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numpy arrays and modifying to fit with sklearn formats\n",
    "#train.dropna(inplace= True)\n",
    "\n",
    "train = df[32:200000]\n",
    "test = df[200001:240000]\n",
    "val = df[240001:]\n",
    "\n",
    "train_np = train.to_numpy()\n",
    "test_np = test.to_numpy()\n",
    "val_np = val.to_numpy()\n",
    "\n",
    "x_train = train_np[:,:30]\n",
    "y_train = train_np[:, -1]\n",
    "x_test = test_np[:,:30]\n",
    "y_test = test_np[:, -1]\n",
    "x_val = val_np[:,:30]\n",
    "y_val = val_np[:, -1]\n",
    "\n",
    "#x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam\\Desktop\\WGU\\Capstone\\Project\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# logistic regression with base data\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(x_train, y_train)\n",
    "\n",
    "training_accuracy = logistic_model.score(x_train, y_train)\n",
    "#print(\"Training Accuracy:\", training_accuracy)\n",
    "\n",
    "test_accuracy = logistic_model.score(x_test, y_test)\n",
    "#print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "base_log = classification_report(y_test,logistic_model.predict(x_test), target_names=['Legitimate', 'Fraudulent'])\n",
    "#print(base_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Shallow neural network with base data\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train.shape[1],)), \n",
    "    Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy']);\n",
    "\n",
    "stdout_original = sys.stdout\n",
    "sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=2048, epochs=30, validation_data=(x_val, y_val));\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test);\n",
    "print(\"Test Loss:\", test_loss);\n",
    "print(\"Test Accuracy:\", test_accuracy);\n",
    "\n",
    "y_prob = model.predict(x_test);\n",
    "y_pred = (y_prob > 0.5).astype(int);\n",
    "\n",
    "base_snn = classification_report(y_test, y_pred);\n",
    "#print(base_snn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming you have already defined and prepared your features (X) and target (y)\n",
    "x = new_df.drop(['class'], axis=1)\n",
    "y = new_df['class']\n",
    "\n",
    "# Step 1: Instantiate the RandomUnderSampler\n",
    "under_sampler = RandomUnderSampler()\n",
    "\n",
    "# Step 2: Fit and transform the data to perform undersampling\n",
    "x_resampled, y_resampled = under_sampler.fit_resample(x, y)\n",
    "\n",
    "resampled_df = resampled_df = pd.DataFrame(data=x_resampled, columns=x.columns)\n",
    "resampled_df['class'] = y_resampled\n",
    "\n",
    "resampled_df = resampled_df.sample(frac=1)\n",
    "\n",
    "#resampled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_train = resampled_df[32:700]\n",
    "resampled_test = resampled_df[701:850]\n",
    "resampled_val = resampled_df[851:984]\n",
    "\n",
    "\n",
    "train_np_b = resampled_train.to_numpy()\n",
    "test_np_b = resampled_test.to_numpy()\n",
    "val_np_b = resampled_val.to_numpy()\n",
    "\n",
    "\n",
    "x_train_b = train_np_b[:,:30]\n",
    "y_train_b = train_np_b[:, -1]\n",
    "x_test_b = test_np_b[:,:30]\n",
    "y_test_b = test_np_b[:, -1]\n",
    "x_val_b = val_np_b[:,:30]\n",
    "y_val_b = val_np_b[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression with balanced data\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_model.fit(x_train_b, y_train_b)\n",
    "\n",
    "training_accuracy = logistic_model.score(x_train_b, y_train_b)\n",
    "#print(\"Training Accuracy:\", training_accuracy)\n",
    "\n",
    "test_accuracy = logistic_model.score(x_test_b, y_test_b)\n",
    "#print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "balanced_log = classification_report(y_test_b,logistic_model.predict(x_test_b), target_names=['Legitimate', 'Fraudulent'])\n",
    "#print(balanced_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shallow neural network with balanced data\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(x_train_b.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_b, y_train_b, batch_size=1024, epochs=40, validation_data=(x_val, y_val))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_b, y_test_b)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "y_prob = model.predict(x_test_b)\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "balanced_snn = classification_report(y_test_b, y_pred)\n",
    "#print(balanced_snn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(report, title):\n",
    "    lines = report.split('\\n')[2:-5]  # Skip the first 2 lines and last 5 lines\n",
    "    class_names = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score = []\n",
    "\n",
    "    for line in lines:\n",
    "        t = line.strip().split()\n",
    "        class_names.append(t[0])\n",
    "        precision.append(float(t[1]))\n",
    "        recall.append(float(t[2]))\n",
    "        f1_score.append(float(t[3]))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    bar_width = 0.2\n",
    "    index = range(len(class_names))\n",
    "\n",
    "    ax.bar(index, precision, width=bar_width, label='Precision', color='b')\n",
    "    ax.bar([i + bar_width for i in index], recall, width=bar_width, label='Recall', color='g')\n",
    "    ax.bar([i + 2 * bar_width for i in index], f1_score, width=bar_width, label='F1-Score', color='r')\n",
    "\n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(0.5, 1)\n",
    "    ax.set_xticks([i + bar_width for i in index])\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming you have four classification reports named 'report1', 'report2', 'report3', and 'report4'\n",
    "# Replace these with your actual classification reports\n",
    "report1 = base_log\n",
    "\n",
    "report2 = base_snn\n",
    "\n",
    "report3 = balanced_log\n",
    "\n",
    "report4 = balanced_snn\n",
    "\n",
    "def generateGraphThree():\n",
    "#Plot the graphs for each classification report\n",
    "    plot_classification_report(report1, \"Base Data Logistic Regression\")\n",
    "    plot_classification_report(report2, \"Base Data Shallow NN\")\n",
    "    plot_classification_report(report3, \"Balanced Data Logistic Regression\")\n",
    "    plot_classification_report(report4, \"Balanced Data Shallow NN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a Graph to View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b23f0d426349a88d7702391b9b3d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Graph:', options=('All Data Histograms', 'Amounts of Legitimate and Fraudulent Trâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ea83e806f84fdcb6aff18e796658c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Dropdown widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=['All Data Histograms', 'Amounts of Legitimate and Fraudulent Transactions', 'Machine Learning Model Comparisons'],\n",
    "    value='All Data Histograms',\n",
    "    description='Select Graph:'\n",
    ")\n",
    "display(dropdown)\n",
    "\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def update_graph(change):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        selected_graph = dropdown.value\n",
    "        if selected_graph == 'All Data Histograms':\n",
    "            for column_name in df.columns:\n",
    "                generateGraphOne(column_name)\n",
    "        elif selected_graph == 'Amounts of Legitimate and Fraudulent Transactions':\n",
    "            generateGraphTwo()\n",
    "        elif selected_graph == 'Machine Learning Model Comparisons':\n",
    "            generateGraphThree()\n",
    "\n",
    "update_graph(None)\n",
    "dropdown.observe(update_graph, names='value')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
